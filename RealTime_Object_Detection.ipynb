{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs real-time object detection using the YOLO model, displaying bounding boxes and labels for different classes with specific colors on a video feed streamed from a mobile device.\n",
    "\n",
    "This command resolves version issues by installing specific versions of torch, torchvision, and torchaudio with CUDA 11.8 support:\n",
    "\n",
    "* pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained YOLOv5 model (last.pt)\n",
    "model = YOLO(\"last.pt\")\n",
    "\n",
    "# Dictionary with colors for each class\n",
    "class_colors = {\n",
    "    \"Person\": (255, 0, 0),          # Blue\n",
    "    \"Car\": (0, 255, 0),             # Green\n",
    "    \"Motorcycle\": (0, 0, 255),      # Red\n",
    "    \"Bicycle\": (255, 255, 0),       # Cyan\n",
    "    \"Truck\": (255, 0, 255),         # Magenta\n",
    "    \"Bus\": (255, 165, 0),           # Orange\n",
    "    \"Sign\": (0, 255, 255),          # Yellow\n",
    "    \"TrafficLight\": (255, 255, 0)   # cyan\n",
    "}\n",
    "\n",
    "# Video capture from mobile\n",
    "cap = cv2.VideoCapture(\"http://192.168.15.3:8080/video\")\n",
    "\n",
    "# Configure the window to be resizable\n",
    "cv2.namedWindow(\"YOLO Object Detection\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Alternative 1: Automatically maximize the window\n",
    "cv2.setWindowProperty(\"YOLO Object Detection\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection with the YOLOv5 model\n",
    "    results = model(frame)\n",
    "\n",
    "    # Display bounding boxes and labels\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Box coordinates\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # Coordinates (xmin, ymin, xmax, ymax)\n",
    "            confidence = box.conf[0]  # Prediction confidence\n",
    "            class_id = int(box.cls[0])  # Class ID\n",
    "\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                class_name = model.names[class_id]  # Class name\n",
    "                label = f\"{class_name}: {confidence:.2f}\"\n",
    "                \n",
    "                # Choose the corresponding color for the class\n",
    "                color = class_colors.get(class_name, (255, 255, 255))  # White as the default color\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                # Add the label\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Display the video feed with detections\n",
    "    cv2.imshow(\"YOLO Object Detection\", frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs real-time object detection using the YOLO model on a video file, saving the processed video with bounding boxes and labels for different classes with specific colors. Unlike the previous code, this version processes a video file and saves the output to a new video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained YOLOv5 model (last.pt)\n",
    "model = YOLO(\"last.pt\")\n",
    "\n",
    "# Dictionary with colors for each class\n",
    "class_colors = {\n",
    "    \"Person\": (255, 0, 0),          # Blue\n",
    "    \"Car\": (0, 255, 0),             # Green\n",
    "    \"Motorcycle\": (0, 0, 255),      # Red\n",
    "    \"Bicycle\": (255, 255, 0),       # Cyan\n",
    "    \"Truck\": (255, 0, 255),         # Magenta\n",
    "    \"Bus\": (255, 165, 0),           # Orange\n",
    "    \"Sign\": (0, 255, 255),          # Yellow\n",
    "    \"TrafficLight\": (255, 255, 0)   # cyan\n",
    "}\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"video_file.mp4\")  # Use the path to your video file\n",
    "\n",
    "# Check if the video file was opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Get the video frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create a VideoWriter object to save the processed video\n",
    "output_video = cv2.VideoWriter(\"output_video.mp4\", \n",
    "                               cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                               30,  # Frames per second (fps)\n",
    "                               (frame_width, frame_height))  # Frame size\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection with the YOLOv5 model\n",
    "    results = model(frame)\n",
    "\n",
    "    # Display bounding boxes and labels\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Box coordinates\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # Coordinates (xmin, ymin, xmax, ymax)\n",
    "            confidence = box.conf[0]  # Prediction confidence\n",
    "            class_id = int(box.cls[0])  # Class ID\n",
    "\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                class_name = model.names[class_id]  # Class name\n",
    "                label = f\"{class_name}: {confidence:.2f}\"\n",
    "                \n",
    "                # Choose the corresponding color for the class\n",
    "                color = class_colors.get(class_name, (255, 255, 255))  # White as the default color\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                # Add the label\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Write the frame with detections to the output video\n",
    "    output_video.write(frame)\n",
    "\n",
    "    # Optionally, you can display the frame\n",
    "    # cv2.imshow(\"YOLO Object Detection\", frame)\n",
    "\n",
    "    # Press 'q' to stop the process early\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
